% This script demonstrates how to use:
% the proposed EM algorithm + pose dictionary learned from Human3.6M
% + the most recent CNN based 2D detector "Hourglass network"
% (https://github.com/anewell/pose-hg-demo)
% to reconstruct 3D human poses from a sequence of images 
% The images should have been centered at the subject and cropped
% and all cropped images are saved in a folder
% the heatmaps can be generated by running the HG model:
% (1) go to pose-hg-demo folder
% (2) run in command line 
%     > bash model.sh
%     to download the pre-trained hourglass model
% (3) run in command line: 
%     > th run-hg.lua ImageFolderName ImageFileExtension
% for example: th run-hg.lua ../data/tennis jpg
% make sure Torch has been installed and run correctly

clear
startup

%%

datapath = 'data/tennis/';

% read images
filelist = dir([datapath '/*.jpg']);
imagelist = {filelist.name};
nImg = length(imagelist);
image = [];
for i = 1:nImg
    image = cat(4,image,imread(sprintf('%s/%s',datapath,imagelist{i})));
end

% read heatmaps generated by the Hourglass model
% and stack the heatmaps of all frames
heatmap = [];
for i = 1:nImg
    hm = hdf5read(sprintf('%s/%s.h5',datapath,imagelist{i}(1:end-4)),'heatmap');
    % transpose heatmaps to make it consistent with the MATLAB x-y directions
    heatmap = cat(4,heatmap,permute(hm,[2,1,3]));
end

%% load dictionary learned from Human3.6M or CMU

% dict = load('dict/poseDict-all-K128'); % a general pose dict
% dictDataset = 'hm36m';
dict = load('dict/tennis_forehand.mat'); % a motion-specific dict
dictDataset = 'cmu';

% convert dictionary format 
% because the joint order in MPII is different from that in Human3.6M
dict = getMPIIdict(dict,dictDataset);
numKp = length(dict.skel.tree);

%% EM
output = PoseFromVideo('heatmap',heatmap,'dict',dict);
% get estimated poses coordinates for EM output
% the estimated 2D joint location is w.r.t. the bounding box
% need to be converted to the original image coordinates
preds_2d = zeros(2,16,nImg);
preds_3d = zeros(3,16,nImg);
for i = 1:nImg
    center = [size(image,2);size(image,1)]/2;
    scale = size(image,1)/200;
    preds_2d(:,:,i) = transformMPII(output.W_final(2*i-1:2*i,:),center,scale,[size(heatmap,1) size(heatmap,2)],1);
    preds_3d(:,:,i) = output.S_final(3*i-2:3*i,:);
end

%% visualize

nPlot = 4;
figure('position',[300 300 200*nPlot 200]);

for i = 1:nImg
    
    clf

    subplot(1,nPlot,1);
    imshow(image(:,:,:,i));

    subplot(1,nPlot,2);
    imagesc(mat2gray(sum(heatmap(:,:,:,i),3)));
    axis equal off

    subplot(1,nPlot,3);
    imshow(image(:,:,:,i));
    vis2Dskel(preds_2d(:,:,i),dict.skel);

    subplot(1,nPlot,4);
    vis3Dskel(preds_3d(:,:,i),dict.skel,'viewpoint',[-90 0]);
    
    pause(0.01)

end

